{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import make_scorer, r2_score, mean_squared_error, median_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbrev = pd.read_csv(\"data/abbrev.csv\")\n",
    "abbrev = abbrev.drop('Unnamed: 0', axis=1)\n",
    "predictors = ['household_size', 'empl_agriculture', 'empl_professional','empl_social', 'empl_services', 'empl_manufacturing', 'empl_retail',\n",
    "              'prc_fam_poverty', 'avg_income', 'prc_public_transp', 'population', 'pop_65_plus', 'health_ins', 'area', \n",
    "              'domestic_passengers', 'intl_passengers', 'prc_obese', 'ten_plus', 'order', 'density', 'cases_march1',\n",
    "             'cases_march15']\n",
    "# omitting april1 cases data, since it's pretty much perfectly correlated...\n",
    "\n",
    "predictors_noCaseData = predictors.copy()\n",
    "predictors_noCaseData.remove('cases_march1')\n",
    "predictors_noCaseData.remove('cases_march15')\n",
    "\n",
    "abbrev.loc[abbrev[\"intl_passengers\"] == 0, \"intl_passengers\"] = 0.0000001\n",
    "abbrev.loc[abbrev[\"domestic_passengers\"] == 0, \"domestic_passengers\"] = 0.0000001\n",
    "abbrev.loc[abbrev[\"cases_march1\"] == 0, \"cases_march1\"] = 0.0000001\n",
    "abbrev.loc[abbrev[\"cases_march15\"] == 0, \"cases_march15\"] = 0.0000001\n",
    "\n",
    "transform = [\"population\", \"density\", \"intl_passengers\", \"domestic_passengers\", \"area\", \n",
    "            \"cases_march1\", \"cases_march15\"]\n",
    "for field in transform:\n",
    "    abbrev[\"log_\"+field] = np.log1p(abbrev[field])\n",
    "    \n",
    "log_predictors = predictors.copy()\n",
    "for field in transform:\n",
    "    log_predictors.remove(field)\n",
    "    log_predictors.append(\"log_\"+field)\n",
    "    \n",
    "log_predictors_noCaseData = log_predictors.copy()\n",
    "log_predictors_noCaseData.remove('log_cases_march1')\n",
    "log_predictors_noCaseData.remove('log_cases_march15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_name(feature_set, name):\n",
    "    number = re.compile(\"x(\\d+)\")\n",
    "    matched = number.match(name)\n",
    "    if matched:\n",
    "        n = int(matched.group(1))\n",
    "        col_name = feature_set[n]\n",
    "    else:\n",
    "        col_name = \"X\"\n",
    "    return col_name\n",
    "\n",
    "def transform_name(feature_set, name):\n",
    "    interaction = re.compile(\"(\\w+) (\\w+)\")\n",
    "    matched = interaction.match(name)\n",
    "    col_name = \"\"\n",
    "    if matched:\n",
    "        name1 = get_col_name(feature_set, matched.group(1))\n",
    "        name2 = get_col_name(feature_set, matched.group(2))\n",
    "        col_name = name1 + \":\" + name2\n",
    "    else:\n",
    "        col_name = get_col_name(feature_set, name)\n",
    "    return col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(interaction_only=True)\n",
    "scaler = StandardScaler()\n",
    "# https://stats.stackexchange.com/questions/29781/when-conducting-multiple-regression-when-should-you-center-your-predictor-varia\n",
    "# https://stats.stackexchange.com/questions/25690/multiple-linear-regression-for-hypothesis-testing#25707\n",
    "\n",
    "scaler.fit(abbrev[predictors])\n",
    "inter = pd.DataFrame(poly.fit_transform(scaler.transform(abbrev[predictors])), \n",
    "                     columns=[transform_name(predictors, x) for x in poly.get_feature_names()])\n",
    "\n",
    "scaler.fit(abbrev[predictors_noCaseData])\n",
    "inter_noCases = pd.DataFrame(poly.fit_transform(scaler.transform(abbrev[predictors_noCaseData])), \n",
    "                             columns=[transform_name(predictors_noCaseData, x) for x in poly.get_feature_names()])\n",
    "\n",
    "scaler.fit(abbrev[log_predictors])\n",
    "inter_log = pd.DataFrame(poly.fit_transform(scaler.transform(abbrev[log_predictors])), \n",
    "                         columns=[transform_name(log_predictors, x) for x in poly.get_feature_names()])\n",
    "\n",
    "scaler.fit(abbrev[log_predictors_noCaseData])\n",
    "inter_log_noCases = pd.DataFrame(poly.fit_transform(scaler.transform(abbrev[log_predictors_noCaseData])), \n",
    "                                 columns=[transform_name(log_predictors_noCaseData, x) for x in poly.get_feature_names()])\n",
    "\n",
    "inter = inter.drop(\"X\", axis=1)\n",
    "inter_noCases = inter_noCases.drop(\"X\", axis=1)\n",
    "inter_log = inter_log.drop(\"X\", axis=1)\n",
    "inter_log_noCases = inter_log_noCases.drop(\"X\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbrev[\"log_deaths\"] = np.log1p(abbrev[\"deaths\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [abbrev[predictors_noCaseData], abbrev[predictors], abbrev[log_predictors_noCaseData], abbrev[log_predictors],  \n",
    "          inter_noCases, inter, inter_log_noCases,  inter_log]\n",
    "labels = [\"no case data\", \"with case data\", \"log predictors, no case data\", \"log predictors, with case data\", \n",
    "          \"no case data, with interactions\", \"with case data, with interactions\", \n",
    "          \"log predictors, no case data, with interactions\", \"log predictors, with case data, with interactions\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR\n",
    "\n",
    "### linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svrl = SVR(kernel=\"linear\")#, C=1.0, epsilon=0.1)\n",
    "for lb, dat in zip(labels, x_data):\n",
    "    svrl.fit(dat, abbrev[\"log_deaths\"])\n",
    "    print(\"{:50} : {:>5.3}\".format(lb,svrl.score(dat, abbrev[\"log_deaths\"])))\n",
    "    \n",
    "    # took hours to not finish..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svrl = SVR(kernel=\"linear\", C=1.0, epsilon=0.1)\n",
    "svrl.fit(x_data[0], abbrev[\"log_deaths\"])\n",
    "print(\"{:50} : {:>5.3}\".format(lb,svrl.score(dat, abbrev[\"log_deaths\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svrl = SVR(kernel=\"rbf\", C=1.0, epsilon=0.1)\n",
    "svrl.fit(x_data[0], abbrev[\"log_deaths\"])\n",
    "print(\"{:50} : {:>5.3}\".format(lb,svrl.score(dat, abbrev[\"log_deaths\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svrl = SVR(kernel=\"sigmoid\", C=1.0, epsilon=0.1)\n",
    "svrl.fit(x_data[0], abbrev[\"log_deaths\"])\n",
    "print(\"{:50} : {:>5.3}\".format(lb,svrl.score(dat, abbrev[\"log_deaths\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svrl = SVR(kernel=\"rbf\", C=1.0, epsilon=0.1)\n",
    "for lb, dat in zip(labels, x_data):\n",
    "    svrl.fit(dat, abbrev[\"log_deaths\"])\n",
    "    print(\"{:50} : {:>5.3}\".format(lb,svrl.score(dat, abbrev[\"log_deaths\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svrl = SVR(kernel=\"sigmoid\", C=1.0, epsilon=0.1)\n",
    "for lb, dat in zip(labels, x_data):\n",
    "    svrl.fit(dat, abbrev[\"log_deaths\"])\n",
    "    print(\"{:50} : {:>5.3}\".format(lb,svrl.score(dat, abbrev[\"log_deaths\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using transformed target/dependent variable\n",
    "score = list()\n",
    "\n",
    "rfr = RandomForestRegressor(random_state=1001)\n",
    "params = {'n_estimators':[50,100,250], \n",
    "          'max_depth':[None,5,10,15]}\n",
    "r2_scorer = make_scorer(r2_score)\n",
    "search = GridSearchCV(rfr, params, scoring=r2_scorer, cv=10)\n",
    "\n",
    "for dat in x_data:\n",
    "    search.fit(dat, abbrev[\"log_deaths\"])\n",
    "    best_params.append(search.best_params_)\n",
    "    best_score.append(search.best_score_)\n",
    "    \n",
    "for a, b, c in zip(labels, best_score, best_params):\n",
    "    print(\"{:50} : {:>5.3}\".format(a, b))\n",
    "    print(c)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
